import json
import jsonlines
import litellm
from models.openai_models import OpenAIModel
import os
from typing import Optional
import uuid


class SelfRefineModel:
    def __init__(self, llm, name):
        self.llm = llm
        self.name = f"SelfRefine_{name}"

    def respond(self, prompts: list[str], constraint_type: Optional[str] = None) -> list[litellm.ModelResponse]:
        # from litellm import completion
        # response = completion(model="gpt-3.5-turbo", messages=messages)

        initial_responses = self.llm.respond(prompts)

        critique_prompts = [f"""You are tasked with identifying whether or not a response generated for a user-provided prompt is successful at satisfying the constraints specified by that user's prompt. If all constraints were addressed sufficiently by the response, then just respond with "No changes are needed." Otherwise, provide a critique that explains how specifically the response fails to satisfy the constraints.

-------

The prompt given to the LLM is:
{prompt}

-------

The response produced by the LLM was:
{response.choices[0].message.content}

-------

Feedback:""" for prompt, response in zip(prompts, initial_responses)]
        critiques = self.llm.respond(critique_prompts)

        refinement_prompts = [f"""You are tasked with refining the response generated by the LLM in order to better satisfy the constraints specified by the user's prompt. Given the original prompt, the original response, and a critique of this response, make minimal changes to the original response to satisfy the constraints while retaining as much of the meaning and structure of the original response as possible.

-------

The prompt given to the LLM is:
{prompt}

-------

The original response produced by the LLM was:
{initial_response.choices[0].message.content}

-------

The critique of this response is:
{critique.choices[0].message.content}

-------

Revised Reponse:""" for (prompt, initial_response, critique) in zip(prompts, initial_responses, critiques)]
        refinement = self.llm.respond(refinement_prompts)

        return refinement